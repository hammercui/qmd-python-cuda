# æ¨ç†å¼•æ“é€‰å‹å†ç¨‹ï¼šä» llama-cpp åˆ° ONNX Runtime

> æ—¥æœŸï¼š2026-02  
> å…³è”æ–‡ä»¶ï¼š`qmd/search/rerank.py`ã€`qmd/llm/engine.py`ã€`docs/deprecated/llama-cpp-python/`

---

## èƒŒæ™¯

QMD-Python çš„ TypeScript åŸç‰ˆï¼ˆ`qmd`ï¼‰ä½¿ç”¨ `llama-cpp` ä½œä¸ºç»Ÿä¸€æ¨ç†å¼•æ“ï¼Œé©±åŠ¨ä¸‰ä¸ªæ¨¡å‹ï¼š

| è§’è‰² | TypeScript æ–¹æ¡ˆ |
|------|----------------|
| Embedding | `embeddinggemma-300M-Q8_0.gguf`ï¼ˆGoogle Gemma 2B, 384dï¼‰|
| Reranker | `qwen3-reranker-0.6b-q8_0.gguf`ï¼ˆQwen3 0.6B, `rankAndSort` APIï¼‰|
| Query Expansion | `qmd-query-expansion-1.7B-q4_k_m.gguf`ï¼ˆQwen3 0.6B Instructï¼‰|

Python ç§»æ¤çš„åˆå§‹ç›®æ ‡æ˜¯ï¼š**æ²¿ç”¨ç›¸åŒçš„ GGUF æ¨¡å‹ + llama-cpp-python å¼•æ“**ï¼Œä¿æŒæ¶æ„å¯¹ç­‰ã€‚

---

## ç¬¬ä¸€é˜¶æ®µï¼šllama-cpp-python æ–¹æ¡ˆ

### æ–¹æ¡ˆæè¿°

ä½¿ç”¨ `llama-cpp-python 0.3.16`ï¼ˆCUDA 12.1 é¢„ç¼–è¯‘ç‰ˆæœ¬ï¼‰ï¼Œé€šè¿‡ GGUF æ ¼å¼åŠ è½½æ‰€æœ‰æ¨¡å‹ã€‚

```python
from llama_cpp import Llama

# Embedding
llama = Llama(model_path="embeddinggemma-300M-Q8_0.gguf", embedding=True)
vec = llama.embed("search query")   # â†’ list[float] 384d

# Reranker
llama_reranker = Llama(model_path="qwen3-reranker-0.6b-q8_0.gguf")
scores = llama_reranker.rankAndSort(query, documents)
```

### Embedding æµ‹è¯•ç»“æœï¼ˆBGE Small English v1.5 Q8_0ï¼‰

BGE Small å…¼å®¹ BERT æ¶æ„ï¼Œllama-cpp-python æ­£å¸¸åŠ è½½ï¼Œæ€§èƒ½ä¼˜ç§€ï¼š

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ¨¡å‹å¤§å° | 35 MB |
| æ˜¾å­˜å ç”¨ | 22 MB |
| åŠ è½½æ—¶é—´ | 142 ms |
| çŸ­æ–‡æœ¬å»¶è¿Ÿ | 5.48 ms |
| ååé‡ | 187 texts/sec |

**ç»“è®ºï¼šBGE å¯ç”¨ï¼Œä½†è¿™æ˜¯è€æ¶æ„ï¼ˆBERTï¼‰çš„ç‰¹ä¾‹ã€‚**

---

## é‡åˆ°çš„å…³é”®é—®é¢˜

### é—®é¢˜ä¸€ï¼šGemma Embedding æ¨¡å‹ä¸å—æ”¯æŒ

åŸç‰ˆ TypeScript ä½¿ç”¨ `embeddinggemma-300M-Q8_0.gguf`ï¼ˆGoogle EmbeddingGemmaï¼ŒåŸºäº Gemma 2Bï¼Œ384 ç»´ï¼‰ï¼Œ  
ä½† `llama-cpp-python 0.3.16` **ä¸æ”¯æŒ** `gemma-embedding` æ¶æ„ï¼š

```
# å°è¯•åŠ è½½ embeddinggemma-300M-Q8_0.gguf æ—¶çš„é”™è¯¯ï¼š
llama_model_load: error loading model: unsupported model architecture: gemma-embedding
```

è¿™æ˜¯æ¶æ„çº§çš„ä¸å…¼å®¹ï¼Œä¸æ˜¯å‚æ•°é—®é¢˜ã€‚

**å½±å“**ï¼šä¸ TypeScript ç‰ˆæœ¬æ— æ³•ä½¿ç”¨åŒä¸€ä¸ª embedding æ¨¡å‹ï¼Œå‘é‡ç»´åº¦ï¼ˆ384dï¼‰ä¹Ÿæ— æ³•å¯¹é½ã€‚

---

### é—®é¢˜äºŒï¼šQwen3 Reranker GGUF å¼ é‡æ•°ä¸åŒ¹é…

å°è¯•åŠ è½½ `qwen3-reranker-0.6b-q8_0.gguf`ï¼ˆä¸ TypeScript ç‰ˆæœ¬ç›¸åŒçš„æ–‡ä»¶ï¼‰ï¼š

```
load_tensors: wrong number of tensors; expected 311, got 310
```

llama-cpp-python 0.3.16 å¯¹ Qwen3 æ¶æ„çš„ GGUF æ ¼å¼æ”¯æŒä¸å®Œæ•´ï¼Œæ¨¡å‹å†…éƒ¨å¼ é‡æ•°é‡ä¸é¢„æœŸä¸ç¬¦ï¼Œæ— æ³•åŠ è½½ã€‚

---

### é—®é¢˜ä¸‰ï¼šæ— å‡çº§è·¯å¾„

å°è¯•å‡çº§ llama-cpp-python ä»¥æ”¯æŒæ–°æ¶æ„ï¼š

```bash
pip install --upgrade llama-cpp-python \
  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```

**ç»“æœ**ï¼šwheel index ä¸Šåªæœ‰ 0.3.16 å’Œæ›´æ—§çš„ 0.3.4ï¼Œæ²¡æœ‰æ›´æ–°çš„ CUDA 12.1 é¢„ç¼–è¯‘ç‰ˆæœ¬ã€‚  
ä»æºç ç¼–è¯‘éœ€è¦æœ¬åœ° CUDA å·¥å…·é“¾ä¸”é£é™©è¾ƒé«˜ï¼Œä¸åœ¨å½“å‰å¼€å‘èµ„æºå†…ã€‚

**å·¥ç¨‹ç›®å½•é—ç•™æ–‡ä»¶**ï¼š
```
docs/deprecated/llama-cpp-python/wheels/
â”œâ”€â”€ llama_cpp_python-0.3.16-cp310-cp310-win_amd64.whl
â””â”€â”€ llama_cpp_python-0.3.4-cp310-cp310-win_amd64.whl
```

---

### é—®é¢˜å››ï¼šæ¶æ„å®šä½ä¸åŒ¹é…

llama-cpp çš„è®¾è®¡ç›®æ ‡æ˜¯**è‡ªå›å½’æ–‡æœ¬ç”Ÿæˆ**ï¼ˆLLaMAã€Mistralã€Qwen ç­‰ï¼‰ï¼Œå…¶ GGUF æ ¼å¼å’Œ `rankAndSort` API  
æ˜¯ä¸ºç”Ÿæˆæ¨¡å‹çš„ logit æ’åºè®¾è®¡çš„ï¼Œå¹¶é cross-encoder ç±» reranker çš„åŸç”Ÿæ ¼å¼ã€‚

ç°ä»£é«˜è´¨é‡ embedding/reranker æ¨¡å‹ï¼ˆJinaã€BGE-M3ã€E5ã€Qwen3-Reranker seq-cls ç­‰ï¼‰ä¸»è¦ä»¥  
Transformer encoder æˆ– seq-cls å½¢å¼åˆ†å‘ï¼ŒGGUF ç¤¾åŒºçš„é‡åŒ–è¦†ç›–æ˜æ˜¾æ»åã€‚

---

## å†³ç­–ï¼šæ”¾å¼ƒ llama-cpp-python

ç»¼åˆä¸Šè¿°é—®é¢˜ï¼Œllama-cpp-python æ–¹æ¡ˆåœ¨å½“æ—¶ï¼ˆ2026-02-19ï¼‰æ­£å¼å½’æ¡£ï¼š

| é—®é¢˜ | ä¸¥é‡ç¨‹åº¦ | æ˜¯å¦å¯è§£ |
|------|----------|----------|
| Gemma embedding æ¶æ„ä¸æ”¯æŒ | ğŸ”´ é˜»æ–­ | å¦ï¼ˆéœ€ç­‰ä¸Šæ¸¸æ”¯æŒï¼‰|
| Qwen3 Reranker å¼ é‡æ•°é”™è¯¯ | ğŸ”´ é˜»æ–­ | å¦ï¼ˆæ— å‡çº§è·¯å¾„ï¼‰|
| æ— æ›´æ–°ç‰ˆé¢„ç¼–è¯‘ wheel | ğŸŸ¡ é«˜ | éœ€æ‰‹åŠ¨ç¼–è¯‘ï¼Œæˆæœ¬é«˜ |
| ç”Ÿæˆæ¨¡å‹å®šä½ â‰  encoder æ¨¡å‹éœ€æ±‚ | ğŸŸ  ä¸­ | æ¶æ„æ€§é—®é¢˜ |

å½’æ¡£ç›®å½•ï¼š`docs/deprecated/llama-cpp-python/`

> **æ³¨**ï¼šllama-cpp-python æœ¬èº«æ²¡æœ‰é—®é¢˜ï¼Œå®ƒåœ¨è‡ªå·±çš„å®šä½ï¼ˆLLM ç”Ÿæˆæ¨ç†ï¼‰ä¸­éå¸¸ä¼˜ç§€ã€‚
> é—®é¢˜åœ¨äº encoder-class æ¨¡å‹ï¼ˆembeddingã€cross-encoder rerankerï¼‰çš„ GGUF æ”¯æŒåœ¨å½“æ—¶å°šæœªæˆç†Ÿã€‚

---

## ç¬¬äºŒé˜¶æ®µï¼šPyTorch + transformers è¿‡æ¸¡æ–¹æ¡ˆ

æ”¾å¼ƒ llama-cpp åï¼Œä¸´æ—¶æ”¹ç”¨ PyTorch ç›´æ¥åŠ è½½ HuggingFace æ¨¡å‹ï¼š

```python
# Rerankerï¼ˆPyTorchï¼‰
from transformers import AutoModelForSequenceClassification, AutoTokenizer
model = AutoModelForSequenceClassification.from_pretrained("Qwen/Qwen3-Reranker-0.6B")

# Expansionï¼ˆPyTorchï¼‰
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-0.5B-Instruct")
```

**é—®é¢˜**ï¼šPyTorch æœ¬èº«çº¦ 2-3 GBï¼ˆCUDA ç‰ˆï¼‰ï¼Œä¸” reranker/expansion æ˜¯ torch çš„å”¯ä¸€ä½¿ç”¨è€…ï¼›  
embedding å·²åˆ‡æ¢åˆ° fastembedï¼ˆONNXï¼‰ï¼Œå¼•å…¥ torch çº¯å±èµ„æºæµªè´¹ã€‚

---

## ç¬¬ä¸‰é˜¶æ®µï¼šå…¨é¢è¿ç§»è‡³ ONNX Runtime

### ä¸ºä»€ä¹ˆé€‰æ‹© ONNX Runtime

| ç»´åº¦ | llama-cpp-python | PyTorch | **ONNX Runtime** |
|------|-----------------|---------|-----------------|
| Embedding æ¨¡å‹æ”¯æŒ | âŒ æ–°æ¶æ„ä¸å…¼å®¹ | âœ… | âœ… |
| Reranker seq-cls æ”¯æŒ | âŒ æ— åŸç”Ÿ API | âœ… | âœ… |
| Causal LM ç”Ÿæˆ | âœ… | âœ… | âœ…ï¼ˆæ‰‹åŠ¨ KV cacheï¼‰|
| CUDA åŠ é€Ÿ | âœ… | âœ… | âœ…ï¼ˆCUDAExecutionProviderï¼‰|
| å®‰è£…ä½“ç§¯ | ~100 MB | ~2-3 GB | ~200 MBï¼ˆonnxruntime-gpuï¼‰|
| torch ä¾èµ– | âŒ æ—  | âœ… å¿…é¡» | âŒ æ— éœ€ï¼ˆfastembed å±‚ç‹¬ç«‹ï¼‰|
| æ¨¡å‹å¯ç”¨æ€§ | GGUF ç¤¾åŒºï¼ˆæ»åï¼‰| HF Hubï¼ˆå®Œæ•´ï¼‰| HF Hub ONNXï¼ˆå®Œæ•´ï¼‰|
| é‡åŒ–æ ¼å¼é€‰æ‹© | ä»… GGUF | FP16/BF16 | INT8 / q4f16 / FP32 |

### æ¨ç†æ€§èƒ½å…³é”®å‘ç°

è¿ç§»è¿‡ç¨‹ä¸­å‘ç°äº† ONNX Runtime çš„ä¸€ä¸ªé‡è¦æ€§èƒ½é™·é˜±ï¼š

**INT8 ONNX æ¨¡å‹åœ¨ CUDA EP ä¸‹çš„ fallback é—®é¢˜**

```
providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
# åŠ è½½ INT8 é‡åŒ–æ¨¡å‹ â†’ å¤§é‡ç®—å­ fallback åˆ° CPU
# æ¯æ¬¡ fallback: GPUæ•°æ® â†’(PCIe ~16GB/s)â†’ CPUè®¡ç®— â†’(PCIe)â†’ GPU
# ç»“æœï¼šæ¯”çº¯ CPU æ¨ç†æ…¢ 10 å€ä»¥ä¸Š
```

å„é‡åŒ–æ ¼å¼åœ¨ä¸åŒ EP ä¸‹çš„å®é™…è¡¨ç°ï¼š

| é‡åŒ–æ ¼å¼ | CPU EP | CUDA EP | åŸå›  |
|---------|--------|---------|------|
| INT8 | âœ… AVX512/VNNI ä¼˜åŒ– | âŒ ç®—å­ fallbackï¼Œææ…¢ | INT8 MatMul æ—  CUDA kernel |
| q4f16 | ğŸŸ¡ ä¸€èˆ¬ | âœ… `MatMulNBits` åŸç”Ÿ CUDA | onnxruntime-gpu â‰¥ 1.17 æ”¯æŒ |
| FP32 | ğŸŸ¡ æ…¢ | âœ… å…¨éƒ¨åŸç”Ÿæ”¯æŒ | æ ‡å‡† CUDA ç®—å­ |

### å„æ¨¡å‹çš„æœ€ç»ˆé€‰å‹

**Embedding**ï¼š`Xenova/jina-embeddings-v2-base-zh`ï¼ŒINT8 ONNXï¼Œ768d  
â†’ fastembed-gpu ç®¡ç†ï¼ŒINT8 embedding ç®—å­ CUDA æ”¯æŒå®Œæ•´ï¼Œæ—  fallback

**Query Expansion**ï¼š`onnx-community/Qwen3-0.6B-ONNX`ï¼Œ**q4f16**  
â†’ æœ¬åœ°å·²æœ‰ 5 ç§æ ¼å¼ï¼ˆFP32/INT8/q4/q4f16/quantizedï¼‰ï¼Œé€‰ q4f16ï¼š  
  - INT8 åœ¨ CUDA ä¸Šææ…¢ï¼ˆfallbackï¼‰ï¼Œq4f16 `MatMulNBits` åŸç”Ÿ CUDA æ”¯æŒ  
  - è€—æ—¶ï¼šINT8 CUDA ~20s â†’ q4f16 CUDA **~1s**

**Reranker**ï¼š`zhiqing/Qwen3-Reranker-0.6B-seq-cls-ONNX`ï¼Œ**FP32 Sequence Classification**  
â†’ è€Œé Causal LM æ ¼å¼ï¼ˆ`thomasht86/Qwen3-Reranker-0.6B-int8-ONNX`ï¼‰  
  - Causal LM æ ¼å¼ï¼šæ¯ç¯‡æ–‡æ¡£å•ç‹¬ forwardï¼Œè¾“å‡º `(1, seq, 151669)` vocab logitsï¼Œä¸²è¡Œ Ã— 10 ç¯‡ ~28s  
  - Seq-Cls æ ¼å¼ï¼šæ‰¹é‡ forwardï¼Œè¾“å‡º `(batch, 1)`ï¼Œä¸€æ¬¡å®Œæˆï¼Œ~0.1-0.3s  
  - FP32 æ‰€æœ‰ç®—å­åŸç”Ÿ CUDAï¼Œæ—  fallback

---

## ä¼˜åŒ–æ—¶é—´çº¿

| æ—¶é—´ | æ–¹æ¡ˆ | POST /query è€—æ—¶ |
|------|------|----------------|
| åˆå§‹ | PyTorch Causal LM reranker + CPU INT8 ONNX | ~26-30s |
| æ”¹ 1 | ONNX INT8 Causal LM rerankerï¼ˆCUDAï¼Œfallbackï¼‰| ~28s |
| æ”¹ 2 | å¼ºåˆ¶ CPU EPï¼ˆINT8 ä¸“ä¸º CPU ä¼˜åŒ–ï¼‰| ~5s |
| æ”¹ 3 | expansion åˆ‡æ¢ q4f16 CUDA | ~4.5s |
| æ”¹ 4 | reranker åˆ‡æ¢ seq-cls FP32 CUDAï¼ˆæ‰¹é‡æ¨ç†ï¼‰| **~1.5-2s** |

---

## ç»éªŒæ€»ç»“

1. **llama-cpp / GGUF ç”Ÿæ€**ï¼šæ“…é•¿ LLM ç”Ÿæˆæ¨ç†ï¼Œencoder-class æ¨¡å‹æ”¯æŒæ»åï¼Œä¸é€‚åˆ embedding/seq-cls reranker åœºæ™¯

2. **Gemma Embedding**ï¼šGoogle çš„ embedding å˜ä½“ï¼ˆ`gemma-embedding` æ¶æ„ï¼‰åœ¨ llama-cpp ä¸­ä¸è¢«æ”¯æŒï¼Œæ˜¯é˜»æ–­æ€§é—®é¢˜

3. **INT8 ONNX çš„ä½¿ç”¨åœºåˆ**ï¼šINT8 é‡åŒ–æ˜¯é’ˆå¯¹ CPU SIMDï¼ˆAVX512/VNNIï¼‰ä¼˜åŒ–çš„ï¼Œä¸é€‚åˆ GPU æ¨ç†ï¼›éœ€è¦ GPU æ¨ç†æ—¶åº”é€‰ q4f16ï¼ˆç”Ÿæˆæ¨¡å‹ï¼‰æˆ– FP32ï¼ˆåˆ†ç±»æ¨¡å‹ï¼‰

4. **æ¨¡å‹æ ¼å¼å†³å®šæ¨ç†æ¨¡å¼**ï¼šCausal LM æ ¼å¼çš„ reranker å¿…é¡»é€ç¯‡ä¸²è¡Œ forwardï¼›Sequence Classification æ ¼å¼å¯æ‰¹é‡å¹¶è¡Œï¼Œæ€§èƒ½å·®è·çº¦ 100 å€

5. **ä¼˜å…ˆè€ƒå¯Ÿæ¨¡å‹è¾“å‡ºå½¢çŠ¶**ï¼šåœ¨é›†æˆä¸€ä¸ªæ–°æ¨¡å‹å‰ï¼Œåº”å…ˆç¡®è®¤å…¶è¾“å‡ºå¼ é‡å½¢çŠ¶ï¼ˆ`session.get_outputs()`ï¼‰ï¼Œé¿å…åœ¨é›†æˆåæ‰å‘ç°æ ¼å¼ä¸åŒ¹é…
